{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BBox.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUjlrQTGPIwo",
        "colab_type": "code",
        "outputId": "a2891b4b-5924-4775-de79-58d1e2009c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP7nqY8SppRT",
        "colab_type": "code",
        "outputId": "cdcf568d-bce0-4ff5-8fd0-67696eac47e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7DnF_9rUJpy",
        "colab_type": "code",
        "outputId": "b70ec5b0-4103-4c91-dd9f-534a921aa922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmW7ki4KUVeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/BOUNDING_BOX\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T232C_D6hq9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data\n",
        "import os\n",
        "from os.path import exists, join, split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class LSUN(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, phase, transforms, list_dir=None,\n",
        "                 out_name=False):\n",
        "        self.list_dir = data_dir if list_dir is None else list_dir\n",
        "        self.data_dir = data_dir\n",
        "        self.out_name = out_name\n",
        "        self.phase = phase\n",
        "        self.transforms = transforms\n",
        "        self.image_list = None\n",
        "        self.label_list = None\n",
        "        self.bbox_list = None\n",
        "        self.read_lists()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = [Image.open(join(self.data_dir, self.image_list[index]))]\n",
        "        data = np.array(data[0])\n",
        "        if len(data.shape) == 2:\n",
        "            data = np.stack([data , data , data] , axis = 2)\n",
        "        data = [Image.fromarray(data)]\n",
        "        # print(data)\n",
        "        if self.label_list is not None:\n",
        "       \t    data.append(Image.open(join(self.data_dir, self.label_list[index])))\n",
        "        data = list(self.transforms(*data))\n",
        "        if self.out_name:\n",
        "            if self.label_list is None:\n",
        "                data.append(data[0][0, :, :])\n",
        "            data.append(self.image_list[index])\n",
        "        return tuple(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def read_lists(self):\n",
        "        image_path = join(self.list_dir, self.phase + '_images.txt')\n",
        "        label_path = join(self.list_dir, self.phase + '_labels.txt')\n",
        "        # print(image_path)\n",
        "        assert exists(image_path)\n",
        "        self.image_list = [line.strip() for line in open(image_path, 'r')]\n",
        "        if exists(label_path):\n",
        "            self.label_list = [line.strip() for line in open(label_path, 'r')]\n",
        "            assert len(self.image_list) == len(self.label_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDmywq4Eimzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "'''\n",
        "custom data transform for LSUN dataset\n",
        "torchvision is not compatible with LSUN\n",
        "'''\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "\n",
        "    def __call__(self, image, label, *args):\n",
        "        assert label is None or image.size == label.size, \\\n",
        "            \"image and label doesn't have the same size {} / {}\".format(\n",
        "                image.size, label.size)\n",
        "\n",
        "        w, h = image.size\n",
        "        tw, th = self.size\n",
        "        top = bottom = left = right = 0\n",
        "        if w < tw:\n",
        "            left = (tw - w) // 2\n",
        "            right = tw - w - left\n",
        "        if h < th:\n",
        "            top = (th - h) // 2\n",
        "            bottom = th - h - top\n",
        "        if left > 0 or right > 0 or top > 0 or bottom > 0:\n",
        "            label = pad_image(\n",
        "                'constant', label, top, bottom, left, right, value=255)\n",
        "            image = pad_image(\n",
        "                'reflection', image, top, bottom, left, right)\n",
        "        w, h = image.size\n",
        "        if w == tw and h == th:\n",
        "            return (image, label, *args)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        results = [image.crop((x1, y1, x1 + tw, y1 + th))]\n",
        "        if label is not None:\n",
        "            results.append(label.crop((x1, y1, x1 + tw, y1 + th)))\n",
        "        results.extend(args)\n",
        "        return results\n",
        "\n",
        "\n",
        "class RandomScale(object):\n",
        "    def __init__(self, scale):\n",
        "        if isinstance(scale, numbers.Number):\n",
        "            scale = [1 / scale, scale]\n",
        "        self.scale = scale\n",
        "\n",
        "    def __call__(self, image, label):\n",
        "        ratio = random.uniform(self.scale[0], self.scale[1])\n",
        "        w, h = image.size\n",
        "        tw = int(ratio * w)\n",
        "        th = int(ratio * h)\n",
        "        if ratio == 1:\n",
        "            return image, label\n",
        "        elif ratio < 1:\n",
        "            interpolation = Image.ANTIALIAS\n",
        "        else:\n",
        "            interpolation = Image.CUBIC\n",
        "        return image.resize((tw, th), interpolation), \\\n",
        "               label.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "\n",
        "class RandomRotate(object):\n",
        "    \"\"\"Crops the given PIL.Image at a random location to have a region of\n",
        "    the given size. size can be a tuple (target_height, target_width)\n",
        "    or an integer, in which case the target will be of a square shape (size, size)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, angle):\n",
        "        self.angle = angle\n",
        "\n",
        "    def __call__(self, image, label=None, *args):\n",
        "        assert label is None or image.size == label.size\n",
        "\n",
        "        w, h = image.size\n",
        "        p = max((h, w))\n",
        "        angle = random.randint(0, self.angle * 2) - self.angle\n",
        "\n",
        "        if label is not None:\n",
        "            label = pad_image('constant', label, h, h, w, w, value=255)\n",
        "            label = label.rotate(angle, resample=Image.NEAREST)\n",
        "            label = label.crop((w, h, w + w, h + h))\n",
        "\n",
        "        image = pad_image('reflection', image, h, h, w, w)\n",
        "        image = image.rotate(angle, resample=Image.BILINEAR)\n",
        "        image = image.crop((w, h, w + w, h + h))\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class RandomHorizontalFlip(object):\n",
        "    \"\"\"Randomly horizontally flips the given PIL.Image with a probability of 0.5\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, image, label):\n",
        "        if random.random() < 0.5:\n",
        "            results = [image.transpose(Image.FLIP_LEFT_RIGHT),\n",
        "                       label.transpose(Image.FLIP_LEFT_RIGHT)]\n",
        "        else:\n",
        "            results = [image, label]\n",
        "        return results\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    \"\"\"Given mean: (R, G, B) and std: (R, G, B),\n",
        "    will normalize each channel of the torch.*Tensor, i.e.\n",
        "    channel = (channel - mean) / std\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = torch.FloatTensor(mean)\n",
        "        self.std = torch.FloatTensor(std)\n",
        "\n",
        "    def __call__(self, image, label=None):\n",
        "        for t, m, s in zip(image, self.mean, self.std):\n",
        "            t.sub_(m).div_(s)\n",
        "        if label is None:\n",
        "            return image,\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "\n",
        "def pad_reflection(image, top, bottom, left, right):\n",
        "    if top == 0 and bottom == 0 and left == 0 and right == 0:\n",
        "        return image\n",
        "    h, w = image.shape[:2]\n",
        "    next_top = next_bottom = next_left = next_right = 0\n",
        "    if top > h - 1:\n",
        "        next_top = top - h + 1\n",
        "        top = h - 1\n",
        "    if bottom > h - 1:\n",
        "        next_bottom = bottom - h + 1\n",
        "        bottom = h - 1\n",
        "    if left > w - 1:\n",
        "        next_left = left - w + 1\n",
        "        left = w - 1\n",
        "    if right > w - 1:\n",
        "        next_right = right - w + 1\n",
        "        right = w - 1\n",
        "    new_shape = list(image.shape)\n",
        "    new_shape[0] += top + bottom\n",
        "    new_shape[1] += left + right\n",
        "    new_image = np.empty(new_shape, dtype=image.dtype)\n",
        "    new_image[top:top+h, left:left+w] = image\n",
        "    new_image[:top, left:left+w] = image[top:0:-1, :]\n",
        "    new_image[top+h:, left:left+w] = image[-1:-bottom-1:-1, :]\n",
        "    new_image[:, :left] = new_image[:, left*2:left:-1]\n",
        "    new_image[:, left+w:] = new_image[:, -right-1:-right*2-1:-1]\n",
        "    return pad_reflection(new_image, next_top, next_bottom,\n",
        "                          next_left, next_right)\n",
        "\n",
        "\n",
        "def pad_constant(image, top, bottom, left, right, value):\n",
        "    if top == 0 and bottom == 0 and left == 0 and right == 0:\n",
        "        return image\n",
        "    h, w = image.shape[:2]\n",
        "    new_shape = list(image.shape)\n",
        "    new_shape[0] += top + bottom\n",
        "    new_shape[1] += left + right\n",
        "    new_image = np.empty(new_shape, dtype=image.dtype)\n",
        "    new_image.fill(value)\n",
        "    new_image[top:top+h, left:left+w] = image\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def pad_image(mode, image, top, bottom, left, right, value=0):\n",
        "    if mode == 'reflection':\n",
        "        return Image.fromarray(\n",
        "            pad_reflection(np.asarray(image), top, bottom, left, right))\n",
        "    elif mode == 'constant':\n",
        "        return Image.fromarray(\n",
        "            pad_constant(np.asarray(image), top, bottom, left, right, value))\n",
        "    else:\n",
        "        raise ValueError('Unknown mode {}'.format(mode))\n",
        "\n",
        "\n",
        "class Pad(object):\n",
        "    \"\"\"Pads the given PIL.Image on all sides with the given \"pad\" value\"\"\"\n",
        "\n",
        "    def __init__(self, padding, fill=0):\n",
        "        assert isinstance(padding, numbers.Number)\n",
        "        assert isinstance(fill, numbers.Number) or isinstance(fill, str) or \\\n",
        "               isinstance(fill, tuple)\n",
        "        self.padding = padding\n",
        "        self.fill = fill\n",
        "\n",
        "    def __call__(self, image, label=None, *args):\n",
        "        if label is not None:\n",
        "            label = pad_image(\n",
        "                'constant', label,\n",
        "                self.padding, self.padding, self.padding, self.padding,\n",
        "                value=255)\n",
        "        if self.fill == -1:\n",
        "            image = pad_image(\n",
        "                'reflection', image,\n",
        "                self.padding, self.padding, self.padding, self.padding)\n",
        "        else:\n",
        "            image = pad_image(\n",
        "                'constant', image,\n",
        "                self.padding, self.padding, self.padding, self.padding,\n",
        "                value=self.fill)\n",
        "        return (image, label, *args)\n",
        "\n",
        "\n",
        "class PadImage(object):\n",
        "    def __init__(self, padding, fill=0):\n",
        "        assert isinstance(padding, numbers.Number)\n",
        "        assert isinstance(fill, numbers.Number) or isinstance(fill, str) or \\\n",
        "               isinstance(fill, tuple)\n",
        "        self.padding = padding\n",
        "        self.fill = fill\n",
        "\n",
        "    def __call__(self, image, label=None, *args):\n",
        "        if self.fill == -1:\n",
        "            image = pad_image(\n",
        "                'reflection', image,\n",
        "                self.padding, self.padding, self.padding, self.padding)\n",
        "        else:\n",
        "            image = ImageOps.expand(image, border=self.padding, fill=self.fill)\n",
        "        return (image, label, *args)\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Converts a PIL.Image or numpy.ndarray (H x W x C) in the range\n",
        "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, pic, label=None):\n",
        "        if isinstance(pic, np.ndarray):\n",
        "            # handle numpy array\n",
        "            img = torch.from_numpy(pic)\n",
        "        else:\n",
        "            # handle PIL Image\n",
        "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
        "            # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
        "            if pic.mode == 'YCbCr':\n",
        "                nchannel = 3\n",
        "            else:\n",
        "                nchannel = len(pic.mode)\n",
        "            img = img.view(pic.size[1], pic.size[0], nchannel)\n",
        "            # put it from HWC to CHW format\n",
        "            # yikes, this transpose takes 80% of the loading time/CPU\n",
        "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
        "        img = img.float().div(255)\n",
        "        if label is None:\n",
        "            return img,\n",
        "        else:\n",
        "            return img, torch.LongTensor(np.array(label, dtype=np.int))\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    \"\"\"Composes several transforms together.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        for t in self.transforms:\n",
        "            args = t(*args)\n",
        "        return args"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDhHIFhMjR_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "# from torchsummaryX import summary\n",
        "from torch.nn import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "class PreTrainedResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, feature_extracting, num_classes=4):\n",
        "    super(PreTrainedResNet, self).__init__()\n",
        "    self.fcn = models.segmentation.fcn_resnet101(pretrained=True)\n",
        "    if feature_extracting:\n",
        "      for param in self.fcn.parameters():\n",
        "          param.requires_grad = False     # Fine tune whole network if requires_grad = true\n",
        "                                          # or use slower learning rate for earlier layers\n",
        "    #modified from models.segmentation.fcn.FCNHead, see\n",
        "    #https://github.com/pytorch/vision/blob/master/torchvision/models/segmentation/fcn.py\n",
        "    self.fcn.classifier = nn.Sequential(\n",
        "      nn.Conv2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "      nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(p=0.1),\n",
        "      nn.Conv2d(128, num_classes, kernel_size=(1, 1), stride=(1, 1)),\n",
        "    )\n",
        "\n",
        "    self.fcn.aux_classifier = nn.Sequential(\n",
        "      nn.Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "      nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(p=0.1),\n",
        "      nn.Conv2d(128, num_classes, kernel_size=(1, 1), stride=(1, 1)),\n",
        "    )\n",
        "    # self.fcn.classifier = models.segmentation.fcn.FCNHead(2048,4)\n",
        "    # self.fcn.aux_classifier = models.segmentation.fcn.FCNHead(1024,4)\n",
        "    self.softmax = nn.LogSoftmax()\n",
        "    # summary(self.fcn,torch.zeros((1,3,480,480)))\n",
        "\n",
        "  def forward(self, x):\n",
        "      input_shape = x.shape[-2:]\n",
        "      # contract: features is a dict of tensors\n",
        "      features = self.fcn.backbone(x)\n",
        "\n",
        "      result = OrderedDict()\n",
        "      x = features[\"out\"]\n",
        "      x = self.fcn.classifier(x)\n",
        "#       x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
        "      result[\"out\"] = x\n",
        "\n",
        "      if self.fcn.aux_classifier is not None:\n",
        "          x = features[\"aux\"]\n",
        "          x = self.fcn.aux_classifier(x)\n",
        "#           x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
        "          result[\"aux\"] = x\n",
        "      return result\n",
        "\n",
        "  def optim_base_parameters(self, memo=None):\n",
        "    for param in self.fcn.backbone.parameters():\n",
        "        yield param\n",
        "\n",
        "  def optim_seg_parameters(self, memo=None):\n",
        "    for param in self.fcn.classifier.parameters():\n",
        "        yield param\n",
        "    for param in self.fcn.aux_classifier.parameters():\n",
        "        yield param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFYRmTpFkqbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as trans\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import cv2\n",
        "import time\n",
        "from matplotlib.colors import ListedColormap\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-2\n",
        "LEARNING_RATE =  0.060611 / 10\n",
        "BATCH_SIZE = 16\n",
        "IM_SIZE = 240\n",
        "CROP_SIZE = 244\n",
        "FEATURE_EXTRACTING = False\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1e-4\n",
        "R_ROT = 15\n",
        "R_SCALE = 1.75\n",
        "GPU = True\n",
        "scriptdir = \"/content/gdrive/My Drive/BOUNDING_BOX\"\n",
        "OUTPUT_DIR = 'output/'\n",
        "DATADIR = 'data/lsun/'\n",
        "def load_data():\n",
        "    train_transform = Compose(\n",
        "        [RandomRotate(R_ROT),\n",
        "        RandomScale(R_SCALE),\n",
        "        RandomCrop(IM_SIZE),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "\n",
        "    val_transform = Compose(\n",
        "        [RandomCrop(IM_SIZE),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "\n",
        "    trainset = LSUN(DATADIR, 'train', train_transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True, num_workers=8, pin_memory=True, drop_last=True)\n",
        "\n",
        "    print(\"Train set size: \"+str(len(trainset)))\n",
        "\n",
        "    valset = LSUN(DATADIR, 'val', val_transform)\n",
        "    valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
        "    print(\"Val set size: \"+str(len(valset)))\n",
        "    return trainloader, valloader\n",
        "\n",
        "def train(resume=False,pretrained=True):\n",
        "    start = time.time()\n",
        "    trainloader, valloader = load_data()\n",
        "    # test(trainloader)\n",
        "    model = PreTrainedResNet(FEATURE_EXTRACTING, num_classes=4)\n",
        "    filename = \"ckpt\" + '.pth.tar'\n",
        "    save_path = os.path.join(scriptdir,OUTPUT_DIR,filename)\n",
        "    if resume: \n",
        "      checkpoint = torch.load(save_path) \n",
        "      model.load_state_dict(checkpoint['state'])\n",
        "    # show_network(model)\n",
        "    if GPU: model = model.cuda()\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "    if GPU: criterion.cuda()\n",
        "    if FEATURE_EXTRACTING:\n",
        "        optimizer = torch.optim.SGD(model.parameters(),lr=LEARNING_RATE*10, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD([{'params':model.optim_base_parameters(), 'lr':LEARNING_RATE},\n",
        "                                {'params':model.optim_seg_parameters(),'lr':LEARNING_RATE*10}],\n",
        "                                momentum=MOMENTUM,\n",
        "                                weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    #learning rate decay\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, int(NUM_EPOCHS * 1), eta_min = 1e-6)\n",
        "\n",
        "    #to resume learning:\n",
        "    start_ep = 0\n",
        "    if resume: start_ep = checkpoint['epoch']\n",
        "    for epoch in range(start_ep, NUM_EPOCHS):\n",
        "        if not FEATURE_EXTRACTING: base_lr, lr = scheduler.get_lr()\n",
        "        if FEATURE_EXTRACTING: lr = scheduler.get_lr()[0]\n",
        "#         print(lr)\n",
        "        logger.info('Epoch: [{0}]\\tlr {1:.06f}'.format(epoch, lr))\n",
        "        train_helper(trainloader, optimizer, model, criterion)\n",
        "        scheduler.step()\n",
        "        validate(valloader, optimizer, model, criterion, epoch)\n",
        "        #save model\n",
        "        state = {'epoch': epoch + 1,\n",
        "                 'state': model.state_dict()}\n",
        "        torch.save(state, save_path)\n",
        "    end = time.time()\n",
        "    print(\"time: \", end - start)\n",
        "\n",
        "def train_helper(trainloader, optimizer, model, criterion):\n",
        "    model.train()\n",
        "    for i, (img, target) in enumerate(trainloader):\n",
        "        # transform target into more pixelized layout image\n",
        "        # not needed atm, res101 interpolates output\n",
        "\n",
        "\n",
        "        small_target = torch.zeros(int(target.size(0)) , int(target.size(1)/8) , int(target.size(2)/8))\n",
        "        for index in range(target.size(0)):\n",
        "            temp = target[index,:,:]\n",
        "            temp = cv2.resize(temp.numpy(),(int(target.size(1)/8) , int(target.size(2)/8)), interpolation=cv2.INTER_NEAREST)\n",
        "            temp = torch.Tensor(temp)\n",
        "            small_target[index,:,:] = temp\n",
        "        target = small_target\n",
        "        target = target.long()\n",
        "        if GPU:\n",
        "            target = target.cuda(async=True)\n",
        "            img = img.cuda()\n",
        "        input_var = Variable(img)\n",
        "        target_var = Variable(target)\n",
        "        # print(\"here\")\n",
        "        # print(img.size())\n",
        "        outputs = model(input_var)\n",
        "        output = outputs['out']\n",
        "        aux_output = outputs['aux']\n",
        "        # print(output.size())\n",
        "        # print(aux_output.size())       \n",
        "        loss1 = criterion(output,target_var)\n",
        "        loss2 = criterion(aux_output,target_var)\n",
        "        loss = loss1 + loss2\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 100 == 0:\n",
        "            print(\"Loss: \", loss.item())\n",
        "\n",
        "def validate(valloader, optimizer, model, criterion, epoch):\n",
        "    epoch_loss = 0.0\n",
        "    model.eval()\n",
        "    for i, (img, target) in enumerate(valloader):\n",
        "        # transform target into more pixelized layout image\n",
        "        # not needed atm, res101 interpolates output\n",
        "\n",
        "        small_target = torch.zeros(int(target.size(0)) , int(target.size(1)/8) , int(target.size(2)/8))\n",
        "        for index in range(target.size(0)):\n",
        "            temp = target[index,:,:]\n",
        "            temp = cv2.resize(temp.numpy(),(int(target.size(1)/8) , int(target.size(2)/8)), interpolation=cv2.INTER_NEAREST)\n",
        "            temp = torch.Tensor(temp)\n",
        "            small_target[index,:,:] = temp\n",
        "        target = small_target\n",
        "        target = target.long()\n",
        "        with torch.no_grad():\n",
        "            if GPU:\n",
        "                target = target.cuda(async=True)\n",
        "                img = img.cuda()\n",
        "            input_var = Variable(img)\n",
        "            target_var = Variable(target)\n",
        "            \n",
        "            outputs = model(input_var)\n",
        "            output = outputs['out']\n",
        "            aux_output = outputs['aux']\n",
        "            loss1 = criterion(output,target_var)\n",
        "            loss2 = criterion(aux_output,target_var)\n",
        "            loss = loss1 + loss2\n",
        "            epoch_loss += loss.item()\n",
        "            if i % 300 == 0:\n",
        "#               print(\"here\")\n",
        "              save_output_images(output, OUTPUT_DIR, epoch)\n",
        "    print(epoch_loss)\n",
        "\n",
        "def show_network(model):\n",
        "    child_counter = 0\n",
        "    for child in model.children():\n",
        "        print(\" child\", child_counter, \"is:\")\n",
        "        print(child)\n",
        "        child_counter += 1\n",
        "    # print(model.fcn.backbone)\n",
        "\n",
        "def test(trainloader):\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "    print(labels.size())\n",
        "    showtensor(labels)\n",
        "\n",
        "def showtensor(tensor):\n",
        "    x = torch.narrow(tensor,0,0,1)\n",
        "    plt.figure()\n",
        "    plt.imshow(x.squeeze().numpy())\n",
        "    plt.show()\n",
        "\n",
        "def save_checkpoint(self, state):\n",
        "        print(\"[*] Saving model to {}\".format(self.ckpt_dir))\n",
        "\n",
        "        filename = self.get_model_name() + '_ckpt.pth.tar'\n",
        "        ckpt_path = os.path.join(self.ckpt_dir, filename)\n",
        "        torch.save(state, ckpt_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98aXlOaiFFKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_output_images(out, output_dir, epoch):\n",
        "    \"\"\"\n",
        "    Saves a given (B x C x H x W) into an image file.\n",
        "    If given a mini-batch tensor, will save the tensor as a grid of images.\n",
        "    \"\"\"\n",
        "    # pdb.set_trace()\n",
        "    _, pred = torch.max(out, 1)\n",
        "    cmap = ListedColormap(['b', 'c', 'y', 'r'])\n",
        "    pred = pred.cpu().data.numpy()\n",
        "    for i in range(4):\n",
        "#       im = Image.fromarray(pred[i].astype(np.uint8))\n",
        "      fn = os.path.join(scriptdir, output_dir, str(epoch) + str(i) + '.png')\n",
        "      plt.imsave(fn, pred[i], cmap=cmap)\n",
        "#       out_dir = split(fn)[0]\n",
        "#       print(out_dir)\n",
        "#       print(\"here2\")\n",
        "#       im.save(fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m73SgNNNlgKf",
        "colab_type": "code",
        "outputId": "7995331f-2018-4b6b-dccc-179c677e299b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "logging.basicConfig(format = '[%(asctime)-15s %(filename)s:%(lineno)d %(funcName)s] %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(level=logging.DEBUG)\n",
        "train(resume=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set size: 4000\n",
            "Val set size: 394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100%|██████████| 178728960/178728960 [00:03<00:00, 47152363.02it/s]\n",
            "Downloading: \"https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth\" to /root/.cache/torch/checkpoints/fcn_resnet101_coco-7ecb50ca.pth\n",
            "100%|██████████| 217800805/217800805 [00:04<00:00, 53300713.12it/s]\n",
            "[2019-07-26 21:25:04,108 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [53]\tlr 0.060611\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.5587717294692993\n",
            "Loss:  1.0591323375701904\n",
            "Loss:  0.8005150556564331\n",
            "23.669366896152496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 21:38:58,387 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [54]\tlr 0.060581\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8489469289779663\n",
            "Loss:  0.6324933767318726\n",
            "Loss:  0.6755504608154297\n",
            "23.59914129972458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 21:52:12,240 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [55]\tlr 0.060506\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6396154761314392\n",
            "Loss:  0.9856553077697754\n",
            "Loss:  0.9494078159332275\n",
            "24.586486995220184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 22:05:26,355 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [56]\tlr 0.060402\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7595691680908203\n",
            "Loss:  0.9766789674758911\n",
            "Loss:  1.0001049041748047\n",
            "25.11613667011261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 22:18:39,808 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [57]\tlr 0.060268\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7674596905708313\n",
            "Loss:  1.1259868144989014\n",
            "Loss:  0.7910767793655396\n",
            "26.18200945854187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 22:31:51,783 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [58]\tlr 0.060104\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.601533830165863\n",
            "Loss:  0.7596777677536011\n",
            "Loss:  0.8185133337974548\n",
            "23.993260324001312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 22:45:05,095 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [59]\tlr 0.059911\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9957435131072998\n",
            "Loss:  0.7433469891548157\n",
            "Loss:  0.6832413077354431\n",
            "24.46596586704254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 22:58:16,950 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [60]\tlr 0.059689\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8564034104347229\n",
            "Loss:  0.9949761033058167\n",
            "Loss:  0.9590249061584473\n",
            "25.032505214214325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 23:11:28,024 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [61]\tlr 0.059437\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7788987159729004\n",
            "Loss:  0.8690156936645508\n",
            "Loss:  0.736204981803894\n",
            "25.00237262248993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 23:24:40,006 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [62]\tlr 0.059158\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8259851932525635\n",
            "Loss:  0.7821835279464722\n",
            "Loss:  1.1164301633834839\n",
            "25.060912311077118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 23:37:51,958 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [63]\tlr 0.058849\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7649483680725098\n",
            "Loss:  0.9850718975067139\n",
            "Loss:  0.9511522054672241\n",
            "26.35239428281784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-26 23:51:04,607 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [64]\tlr 0.058513\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8406201601028442\n",
            "Loss:  0.7138664722442627\n",
            "Loss:  0.7788923382759094\n",
            "25.605432212352753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 00:04:17,422 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [65]\tlr 0.058148\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6022274494171143\n",
            "Loss:  0.7501447200775146\n",
            "Loss:  0.7456847429275513\n",
            "24.438313961029053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 00:17:29,768 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [66]\tlr 0.057757\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.5967096090316772\n",
            "Loss:  1.082270860671997\n",
            "Loss:  0.7681258916854858\n",
            "23.836846888065338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 00:30:42,884 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [67]\tlr 0.057338\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.867962121963501\n",
            "Loss:  0.8081094026565552\n",
            "Loss:  0.8864725828170776\n",
            "23.688660204410553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 00:43:43,910 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [68]\tlr 0.056892\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9485336542129517\n",
            "Loss:  0.7458368539810181\n",
            "Loss:  1.0633541345596313\n",
            "24.298508405685425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 00:56:44,207 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [69]\tlr 0.056420\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9776017665863037\n",
            "Loss:  0.7568588256835938\n",
            "Loss:  0.8785345554351807\n",
            "25.18250662088394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 01:09:44,135 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [70]\tlr 0.055923\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9198561310768127\n",
            "Loss:  0.7163761854171753\n",
            "Loss:  0.7876248359680176\n",
            "24.668225586414337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 01:22:48,595 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [71]\tlr 0.055400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7384495735168457\n",
            "Loss:  0.8423690795898438\n",
            "Loss:  1.5445353984832764\n",
            "25.674438178539276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 01:35:48,973 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [72]\tlr 0.054853\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6160446405410767\n",
            "Loss:  0.9179404377937317\n",
            "Loss:  1.1156952381134033\n",
            "25.061503469944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 01:48:50,582 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [73]\tlr 0.054281\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7808234691619873\n",
            "Loss:  0.7469685077667236\n",
            "Loss:  1.0376887321472168\n",
            "25.434719264507294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 02:01:53,424 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [74]\tlr 0.053686\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6034609079360962\n",
            "Loss:  0.9336363077163696\n",
            "Loss:  0.9253958463668823\n",
            "25.218169033527374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 02:14:57,736 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [75]\tlr 0.053068\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8811352252960205\n",
            "Loss:  0.9748326539993286\n",
            "Loss:  0.7614986896514893\n",
            "23.68801349401474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 02:27:57,678 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [76]\tlr 0.052427\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9278544783592224\n",
            "Loss:  1.1872354745864868\n",
            "Loss:  1.1593211889266968\n",
            "26.911552011966705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 02:40:58,189 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [77]\tlr 0.051764\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7272768020629883\n",
            "Loss:  0.7128598690032959\n",
            "Loss:  0.6564820408821106\n",
            "23.94730681180954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 02:53:59,330 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [78]\tlr 0.051081\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9999911785125732\n",
            "Loss:  0.8449336886405945\n",
            "Loss:  0.6249958276748657\n",
            "25.689400792121887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 03:07:01,368 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [79]\tlr 0.050377\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8125381469726562\n",
            "Loss:  0.8867375254631042\n",
            "Loss:  0.964881420135498\n",
            "26.28086632490158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 03:20:02,021 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [80]\tlr 0.049653\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7055585980415344\n",
            "Loss:  0.860019326210022\n",
            "Loss:  0.6597006320953369\n",
            "23.34354329109192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 03:33:05,171 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [81]\tlr 0.048910\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6395589113235474\n",
            "Loss:  0.7936432361602783\n",
            "Loss:  0.6152814626693726\n",
            "26.16334581375122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 03:46:04,831 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [82]\tlr 0.048148\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7560339570045471\n",
            "Loss:  0.8580309748649597\n",
            "Loss:  0.6004670858383179\n",
            "24.377289414405823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 03:59:05,624 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [83]\tlr 0.047369\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7607266902923584\n",
            "Loss:  0.7684676051139832\n",
            "Loss:  0.7410062551498413\n",
            "25.94678008556366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 04:12:04,438 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [84]\tlr 0.046574\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  1.0829421281814575\n",
            "Loss:  0.7009278535842896\n",
            "Loss:  0.8556714653968811\n",
            "25.74988079071045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 04:25:03,081 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [85]\tlr 0.045762\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.9239708185195923\n",
            "Loss:  0.8736264705657959\n",
            "Loss:  0.8729934692382812\n",
            "24.32677513360977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 04:38:03,621 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [86]\tlr 0.044935\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8519985675811768\n",
            "Loss:  0.7167798280715942\n",
            "Loss:  0.668358325958252\n",
            "25.90864408016205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 04:51:06,393 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [87]\tlr 0.044094\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.5907591581344604\n",
            "Loss:  0.5744527578353882\n",
            "Loss:  0.7146283388137817\n",
            "25.23999261856079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 05:04:06,663 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [88]\tlr 0.043239\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7659968733787537\n",
            "Loss:  0.9271946549415588\n",
            "Loss:  0.941476047039032\n",
            "25.563752233982086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 05:17:07,079 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [89]\tlr 0.042371\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7008605599403381\n",
            "Loss:  0.6059442758560181\n",
            "Loss:  0.8964370489120483\n",
            "26.90019130706787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 05:30:08,678 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [90]\tlr 0.041491\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.550391435623169\n",
            "Loss:  0.7417958974838257\n",
            "Loss:  1.0001916885375977\n",
            "25.97238427400589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 05:43:11,507 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [91]\tlr 0.040601\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  1.2215006351470947\n",
            "Loss:  0.8601037263870239\n",
            "Loss:  0.9510480165481567\n",
            "29.192290604114532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 05:56:12,258 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [92]\tlr 0.039700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7036756873130798\n",
            "Loss:  0.6564639806747437\n",
            "Loss:  0.5848206877708435\n",
            "24.80268758535385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 06:09:12,513 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [93]\tlr 0.038790\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8831729888916016\n",
            "Loss:  0.6290473937988281\n",
            "Loss:  0.7105491161346436\n",
            "24.947579860687256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 06:22:13,963 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [94]\tlr 0.037872\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.8650531768798828\n",
            "Loss:  1.1112303733825684\n",
            "Loss:  0.8928450345993042\n",
            "23.171476364135742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 06:35:17,521 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [95]\tlr 0.036946\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.807407021522522\n",
            "Loss:  0.7261030077934265\n",
            "Loss:  0.7486476898193359\n",
            "25.817767798900604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 06:48:18,097 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [96]\tlr 0.036014\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7966631650924683\n",
            "Loss:  0.8905484676361084\n",
            "Loss:  0.7419849038124084\n",
            "25.902559280395508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 07:01:18,721 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [97]\tlr 0.035076\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6690472364425659\n",
            "Loss:  0.638717532157898\n",
            "Loss:  0.4562562108039856\n",
            "25.46927058696747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 07:14:19,579 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [98]\tlr 0.034133\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.4710877537727356\n",
            "Loss:  0.632636547088623\n",
            "Loss:  0.4761693775653839\n",
            "27.240716874599457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2019-07-27 07:27:23,526 <ipython-input-8-7896f9ef806a>:86 train] Epoch: [99]\tlr 0.033187\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.7405450940132141\n",
            "Loss:  0.762008547782898\n",
            "Loss:  0.8743240833282471\n",
            "26.99716466665268\n",
            "time:  36945.46297764778\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}